# -*- coding: utf-8 -*-
"""trainc10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rt3rAaWGQxrwrLpujKVbvsx_2UBDB0_m
"""

import sys
sys.path.append('..')
import pandas as pd
import numpy as np
import torch as th
from fastcore.script import *
import scipy.sparse.linalg as sp
import seaborn as sns
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR



bls = th.load('bls.p')

def entropy(x):
    return -th.sum(x * th.log(x + 1e-9), dim=2)




# for bl in bls:
#   yh = th.stack([th.tensor(x['yh'], dtype = th.float32) for x in bl])
#   yvh = th.stack([th.tensor(x['yvh'], dtype = th.float32) for x in bl])
#   f = th.stack([th.tensor(x['f'], dtype = th.float32) for x in bl])
#   fv = th.stack([th.tensor(x['fv'], dtype = th.float32) for x in bl])
#   entropies = entropy(10**yh)
#   entropies_val = entropy(10**yvh)
#   mean_entropy = th.mean(entropies, dim = 1)
#   mean_entropy_val = th.mean(entropies_val, dim = 1)
#   mean_f = th.mean(f, dim= 1)
#   mean_fv = th.mean(fv, dim = 1)
#   plt.plot(mean_entropy, label = 'train')
#   plt.plot(mean_entropy_val, label = 'val')

#   plt.legend()
#   plt.show()

#   plt.plot(mean_f, label = 'train_f')
#   plt.plot(mean_fv, label = 'val_f')

#   plt.legend()
#   plt.show()



print(len(bls))


bls = [bls[0][13], bls[1][15], bls[2][14], bls[3][3], bls[4][12], bls[5][7], bls[6][12], bls[7][2], bls[8][11], bls[9][5]]

bls_hv = th.stack([x['yh'] for x in bls])
bls_hv_val = th.stack([x['yvh'] for x in bls])

bls_hv = bls_hv.permute(1, 0, 2).reshape(50000, -1)

bls_hv_val = bls_hv_val.permute(1, 0, 2).reshape(10000, -1)

print(bls_hv.shape)
print(bls_hv_val.shape)

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms


transform = transforms.ToTensor()
cifar_train = CIFAR10(root='./data', train=True, download=True, transform=transform)

cifar_labels = torch.tensor(cifar_train.targets)
cifar_images = torch.stack([x[0] for x in cifar_train])

class CIFARCustomDataset(Dataset):
    def __init__(self, inputs, logits, labels):
        self.logits = logits
        self.inputs = inputs
        self.labels = labels

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self, idx):
        l = self.logits[idx]
        x = self.inputs[idx]
        y = self.labels[idx]
        return l, x, y


train_dataset = CIFARCustomDataset(cifar_images, bls_hv, cifar_labels)


train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)

cifar_val = CIFAR10(root='./data', train=False, download=True, transform=transform)
cifar_val_labels = torch.tensor(cifar_val.targets)
cifar_val_images = torch.stack([x[0] for x in cifar_val])

val_dataset = CIFARCustomDataset(cifar_val_images, bls_hv_val, cifar_val_labels)
val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False)

import torch
import torch.nn as nn
import torchvision.models as models

import torch
import torch.nn as nn
from typing import List, Dict, Optional
from dataclasses import dataclass

@dataclass
class MetaLearnerConfig:
    hidden_dims: List[int]
    dropout_rate: float = 0.5

class ImageFeatureExtractor(nn.Module):
    def __init__(self, in_channels: int, out_features: int):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),

            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),

            nn.Flatten(),
            nn.Linear(256, out_features),
            nn.BatchNorm1d(out_features),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.features(x)

class MetaLearner(nn.Module):
    """MLP-based meta-learner with configurable architecture"""
    def __init__(self,
                 logits_dim: int,
                 image_features_dim: int,
                 num_classes: int,
                 config: MetaLearnerConfig):
        super().__init__()
        self.combined_dim = logits_dim + image_features_dim

        # Build MLP layers dynamically based on config
        layers = []
        input_dim = self.combined_dim

        for hidden_dim in config.hidden_dims:
            layers.extend([
                nn.Linear(input_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(inplace=True),
                nn.Dropout(config.dropout_rate)
            ])
            input_dim = hidden_dim

        # Final layer
        layers.append(nn.Linear(input_dim, num_classes))

        self.mlp = nn.Sequential(*layers)

    def forward(self, logits_features, image_features):
        combined = torch.cat([logits_features, image_features], dim=1)
        return self.mlp(combined)

class StackedModel(nn.Module):
    """Stacked generalization model using precomputed base learner logits"""
    def __init__(self,
                 meta_config: MetaLearnerConfig,
                 num_classes: int,
                 image_features_dim: int = 256,
                 criterion: Optional[nn.Module] = nn.CrossEntropyLoss(),
                 alpha: float = 1.0):
        super().__init__()
        self.num_classes = num_classes
        self.alpha = alpha


        # Initialize image feature extractor
        self.image_extractor = ImageFeatureExtractor(
            in_channels=3,
            out_features=image_features_dim
        )

        # Initialize meta-learner
        self.meta_learner = MetaLearner(
            logits_dim=num_classes * 10,  # Assuming 10 base learners
            image_features_dim=image_features_dim,
            num_classes=num_classes,
            config=meta_config
        )

        self.criterion = criterion

    def forward(self, x, base_logits: List[torch.Tensor]):
        """
        Args:
            x: Input image tensor of shape [batch_size, 3, H, W].
            base_logits: List of tensors from base learners, each of shape [batch_size, num_classes].
        """
        # Stack base learner logits along the last dimension
        stacked_logits = torch.cat(base_logits, dim=1) 

        # Extract image features
        image_features = self.image_extractor(x)  

        # Get meta-learner prediction
        meta_output = self.meta_learner(stacked_logits, image_features)  

        return {
            'meta_output': meta_output
        }

    def compute_loss(self, outputs: Dict, targets: torch.Tensor) -> Dict:
        meta_loss = self.criterion(outputs['meta_output'], targets)

        return {
            'meta_loss': meta_loss
        }

import torch.optim as optim



meta_config = MetaLearnerConfig(hidden_dims=[128, 64], dropout_rate=0.5)
num_classes = 10
stacked_model = StackedModel(meta_config=meta_config, num_classes=num_classes)
stacked_model = stacked_model.cuda() if torch.cuda.is_available() else stacked_model

# Loss and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(stacked_model.parameters(), lr=0.001, weight_decay=5e-4, momentum = 0.9, nesterov=True)
warmup_epochs = 10
total_steps = len(train_loader) * 100
warmup_steps = len(train_loader) * warmup_epochs


linear_warmup = LinearLR(optimizer, start_factor=0.1, total_iters=warmup_steps)
cosine_annealing = CosineAnnealingLR(optimizer, T_max=total_steps - warmup_steps, eta_min=1e-6)

scheduler = SequentialLR(optimizer, schedulers=[linear_warmup, cosine_annealing], milestones=[warmup_steps])



def train(model, train_loader, val_loader, criterion, optimizer, epochs=5):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0

        for logits, images, labels in train_loader:
            logits, images, labels = logits.to(device), images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images, [logits])
            loss_dict = model.compute_loss(outputs, labels)
            loss = loss_dict['meta_loss']


            loss.backward()
            optimizer.step()
            scheduler.step()

            running_loss += loss.item()

        avg_train_loss = running_loss / len(train_loader)
        #print accuracy
        total = 0
        correct = 0
        model.eval()
        with torch.no_grad():
            for logits, images, labels in train_loader:
                logits, images, labels = logits.to(device), images.to(device), labels.to(device)
                outputs = model(images, [logits])
                _, predicted = torch.max(outputs['meta_output'], 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        accuracy = correct/total * 100
        print(f"Epoch [{epoch + 1}/{epochs}], Train Accuracy: {accuracy:.2f}%")
        print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}")


        # Validation step
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for logits, images, labels in val_loader:
                logits, images, labels = logits.to(device), images.to(device), labels.to(device)

                outputs = model(images, [logits])
                loss_dict = model.compute_loss(outputs, labels) 
                val_loss += loss_dict['meta_loss'].item()

                _, predicted = torch.max(outputs['meta_output'], 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = 100 * correct / total
        print(f"Epoch [{epoch + 1}/{epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\n")
       

# Run the Training Loop
train(stacked_model, train_loader, val_loader, criterion, optimizer, epochs=100)




# plt.imshow(images[2].permute(1, 2, 0))
# plt.title(f"Label: {labels[2]}")
# print(logits[0])
# plt.show()